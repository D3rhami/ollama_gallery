{
  "description": "Qwen2.5 models are pretrained on Alibaba's latest large-scale dataset, encompassing up to 18 trillion tokens. The model supports up to 128K tokens and has multilingual support.",
  "capabilities": [
    "tools"
  ],
  "parameters": [
    "0.5b",
    "1.5b",
    "3b",
    "7b",
    "14b",
    "32b",
    "72b"
  ],
  "pull_str": "18.6M",
  "pull": 18600000,
  "tag_count": 117,
  "updated": "1 year ago",
  "update_date": "2024-12-27",
  "link": "https://ollama.com/library/qwen2.5",
  "popularity": 17
}