{
  "description": "This model extends LLama-3 8B's context length from 8k to over 1m tokens.",
  "capabilities": [],
  "parameters": [
    "8b",
    "70b"
  ],
  "pull_str": "133.5K",
  "pull": 133500,
  "tag_count": "35",
  "updated": "1 year ago",
  "update_date": "2024-12-06",
  "link": "https://ollama.com/library/llama3-gradient",
  "popularity": 124
}