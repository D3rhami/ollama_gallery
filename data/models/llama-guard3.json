{
  "description": "Llama Guard 3 is a series of models fine-tuned for content safety classification of LLM inputs and responses.",
  "capabilities": [],
  "parameters": [
    "1b",
    "8b"
  ],
  "pull_str": "96.9K",
  "pull": 96900,
  "tag_count": 30,
  "updated": "1 year ago",
  "update_date": "2024-11-15",
  "link": "https://ollama.com/library/llama-guard3",
  "popularity": 141
}