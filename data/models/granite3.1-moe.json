{
  "description": "The IBM Granite 1B and 3B models are long-context mixture of experts (MoE) Granite models from IBM designed for low latency usage.",
  "capabilities": [
    "tools"
  ],
  "parameters": [
    "1b",
    "3b"
  ],
  "pull_str": "1.4M",
  "pull": 1400000,
  "tag_count": "33",
  "updated": "10 months ago",
  "update_date": "2025-02-09",
  "link": "https://ollama.com/library/granite3.1-moe",
  "popularity": 47
}