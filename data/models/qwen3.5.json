{
  "description": "The Qwen3.5 series 397B-A17B native vision-language model is built on a hybrid architecture that integrates a linear attention mechanism with a sparse mixture-of-experts model, achieving higher inference efficiency.",
  "capabilities": [
    "vision",
    "tools",
    "thinking"
  ],
  "parameters": [],
  "pull_str": "16K",
  "pull": 16000,
  "tag_count": "2",
  "updated": "1 week ago",
  "update_date": "2026-02-18",
  "link": "https://ollama.com/library/qwen3.5",
  "popularity": 213
}