{
  "description": "The Qwen3.5 series 397B-A17B native vision-language model is built on a hybrid architecture that integrates a linear attention mechanism with a sparse mixture-of-experts model, achieving higher inference efficiency.",
  "capabilities": [
    "vision",
    "tools",
    "thinking"
  ],
  "parameters": [],
  "pull_str": "6,727",
  "pull": 6727,
  "tag_count": 1,
  "updated": "18 hours ago",
  "update_date": "2026-02-16",
  "link": "https://ollama.com/library/qwen3.5",
  "popularity": 213
}